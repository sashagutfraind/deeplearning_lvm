{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a synthetic dataset for demonstrating LVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup\n",
    "\n",
    "```mamba create -n lvm\n",
    "mamba activate lvm\n",
    "mamba install ipykernel pandas\n",
    "ipython kernel install --user --name=lvm\n",
    "\n",
    "https://developer.nvidia.com/cuda-downloads\n",
    "\n",
    "mamba install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "mamba install lightning -c conda-forge\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdb\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import sys, math, copy\n",
    "import time\n",
    "import warnings\n",
    "from typing import Tuple\n",
    "from tempfile import TemporaryFile\n",
    "import numpy as np\n",
    "import numpy.random as npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "cuda_avail = torch.cuda.is_available()\n",
    "print(\"CUDA available: \" + str(cuda_avail))\n",
    "device = torch.device(\"cuda:0\" if cuda_avail else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"synthetic1\"\n",
    "data_dir = \"data\"\n",
    "data_dtype = torch.float32\n",
    "randomseed = 0\n",
    "npr.seed(randomseed)\n",
    "num_histories = 1000\n",
    "\n",
    "num_demo_features = 10  # demographic features - random binary\n",
    "num_var_features = 10   # variable features - random binary\n",
    "\n",
    "mean_start_time = 2010  #when the history starts for a given ID\n",
    "index_time_val = num_demo_features + num_var_features #the location of the time feature\n",
    "\n",
    "max_seq_len = 50 # the length of history, i.e. transformer context window\n",
    "min_seq_len = 2  # for next token prediction, we need at least 1 step + 1 to predict\n",
    "mean_seq_len = 40\n",
    "\n",
    "token_vals = 10  # number of possible tokens, i.e. categories, aka vocab_size\n",
    "index_token_val = num_demo_features + num_var_features + 1\n",
    "\n",
    "padding_val = token_vals  # padding for both token and vector features (+1 not needed)\n",
    "#torch.nan is another option, but it has no value in long(), and cannot be used in any inputs ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random tensor with the specified dimensions\n",
    "random_tensor = torch.randint(0, 2, \n",
    "                              (num_histories, \n",
    "                               max_seq_len, \n",
    "                               num_demo_features + num_var_features \\\n",
    "                                + 1 #time\n",
    "                                + 1 #token\n",
    "                               ), \n",
    "                               dtype=data_dtype,\n",
    "                               device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(random_tensor.shape[0]):    \n",
    "    # fix the demographic features by copying the first value over sequence length\n",
    "    random_tensor[i, :, 0:num_demo_features] = random_tensor[i, 0, 0:num_demo_features].repeat(max_seq_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the start time by taking a random poisson value with mean mean_start_time  \n",
    "random_tensor[:, 0, index_time_val] = torch.from_numpy(np.random.poisson(mean_start_time, num_histories)).to(device)\n",
    "\n",
    "for i in range(random_tensor.shape[0]):    \n",
    "    # increment the time by 1 for each subsequent time step\n",
    "    random_tensor[i, :, index_time_val] = torch.arange(max_seq_len, dtype=data_dtype, device=device) + random_tensor[i, 0, index_time_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The categorical feature (token) is a random integer between 0 and token_vals\n",
    "# Toy case: category is sum the existing features weighted by lag\n",
    "\n",
    "for j in range(random_tensor.shape[1]):\n",
    "    for j2 in range(max(j-5,0), j+1):\n",
    "        random_tensor[:, j, index_token_val] += (1.0/(j-j2+1.0)) * torch.sum(random_tensor[:, j2, 0:num_demo_features + num_var_features], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wishlist: resolve - test does not always pass\n",
    "# print(random_tensor[10, 0, 0:num_demo_features + num_var_features].sum())\n",
    "# print(random_tensor[10, 1, 0:num_demo_features + num_var_features].sum())\n",
    "# print(random_tensor[10, 2, 0:num_demo_features + num_var_features].sum())\n",
    "# print(random_tensor[10, 3, 0:num_demo_features + num_var_features].sum())\n",
    "# print(random_tensor[10, 4, 0:num_demo_features + num_var_features].sum())\n",
    "\n",
    "# print(random_tensor[10, 0, 0:num_demo_features + num_var_features].sum()/5 + \n",
    "#     random_tensor[10, 1, 0:num_demo_features + num_var_features].sum()/4 +\n",
    "#     random_tensor[10, 2, 0:num_demo_features + num_var_features].sum()/3 +\n",
    "#     random_tensor[10, 3, 0:num_demo_features + num_var_features].sum()/2 +\n",
    "#     random_tensor[10, 4, 0:num_demo_features + num_var_features].sum())\n",
    "\n",
    "# print(random_tensor[10, 4, index_token_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the token by rounding the token_val and clipping it to the max token value\n",
    "for i in range(random_tensor.shape[0]):   \n",
    "    random_tensor[i, :, index_token_val] = torch.floor(random_tensor[i, :, index_token_val] % token_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# censor the data series by fixing to padding_val after a poison random time according to the mean_seq_len\n",
    "seq_lengths = np.max([np.random.poisson(mean_seq_len, num_histories), np.ones(num_histories)*min_seq_len], axis=0).astype(int)\n",
    "seq_lengths = np.min([seq_lengths, np.ones(num_histories)*max_seq_len], axis=0).astype(int)\n",
    "\n",
    "for i in range(random_tensor.shape[0]):   \n",
    "    random_tensor[i, seq_lengths[i]:, :] = torch.full((max_seq_len - seq_lengths[i], random_tensor.shape[2]), padding_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "tensor([ 9.,  3.,  6.,  0.,  4.,  4.,  4.,  3.,  5.,  8.,  6.,  6.,  7.,  8.,\n",
      "         4.,  4.,  8.,  8.,  6.,  4.,  3.,  5.,  5.,  8.,  3.,  7.,  6.,  6.,\n",
      "         4.,  2.,  4.,  6.,  3.,  4.,  2.,  6.,  4.,  4.,  3.,  3.,  1.,  3.,\n",
      "         2.,  1.,  3.,  2.,  4.,  3.,  3., 10.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(seq_lengths[10])\n",
    "print(random_tensor[10, 0:seq_lengths[10]+1, index_token_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\synthetic1seed=0_n=1000.pkl\n"
     ]
    }
   ],
   "source": [
    "# save the data to a file\n",
    "fpath = os.path.join(data_dir, dataset_name) + f\"seed={randomseed}_n={num_histories}.pkl\"\n",
    "with open(fpath, 'wb') as f:\n",
    "    pickle.dump(random_tensor, f)\n",
    "print(fpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
